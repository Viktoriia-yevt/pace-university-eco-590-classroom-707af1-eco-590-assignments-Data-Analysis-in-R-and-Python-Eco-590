{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14aebc37-79a7-4d77-96e2-76cfd0babce9",
   "metadata": {},
   "source": [
    "# Course: Intro to Python & R for Data Analysis\n",
    "## Lecture: Let's get this data started - Pandas\n",
    "Professor: Mary Kaltenberg / Anthony Spinelli\n",
    "\n",
    "\n",
    "contact: mkaltenberg@pace.edu\n",
    "\n",
    "contact: aspinelli@pace.edu\n",
    "\n",
    "About Dr. Kaltenberg: www.mkaltenberg.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd8312-6493-4d6a-838e-343c769efc31",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "\n",
    "Part 1 (Quickstart Guide):\n",
    "- dataframes\n",
    "- how to import data into a dataframe\n",
    "- merge\n",
    "- drop columns\n",
    "- combine numpy AND pandas\n",
    "- how to export data\n",
    "\n",
    "Part 2 (Detailed Guide):\n",
    "- concat\n",
    "- transform and pivot\n",
    "- groupby\n",
    "- hierarchial indexing\n",
    "- aggregate\n",
    "\n",
    "\n",
    "\n",
    "<img src ='https://media.giphy.com/media/z6xE1olZ5YP4I/giphy.gif' >\n",
    "\n",
    "Pandas technically comes from \"Panel Data.\" I prefer the dancing pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb6949-bee2-4289-85bb-338f373c0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and call it pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14595da2-e3c2-4d4c-a1ec-493d1bd8558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import data, we use pd.read_csv\n",
    "pd.read_csv('Your path to data here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a22fd3-92db-43ab-9182-3ae334ea8408",
   "metadata": {},
   "source": [
    "# A note about pathing and importing data\n",
    "\n",
    "everybodys paths will be diffrent depending on your own folder system\n",
    "\n",
    "to find paths to stuff, look in your directory (either on the side in jupyter lab or in the home tab on jupyter notebook)\n",
    "\n",
    "to get a path to something, right click and select copy path\n",
    "\n",
    "<img src ='images/get path.png' width=500 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b511f-a4ca-4214-ad79-aa611b2f86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the pwd command in line to get our working path\n",
    "# pwd must be in its own cell if its not working for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded2064-b9f7-4e49-a013-42fd19a7af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef64754-d506-4c91-ba0e-216e088e7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My path here:\n",
    "Desktop/pace-university-eco-590-classroom-707af1-eco-590-assignments-Data-Analysis-in-R-and-Python-Eco-590-main/Lectures/Week_4/ds/wjp.csv\n",
    "\n",
    "# NOtice how the pwd is missing the begining - /Users/anthonyspinelli/\n",
    "# this is known as the complete path, and its good practie at first to use complete or full paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8907fea-11fa-488a-8c7b-06104b38c1dc",
   "metadata": {},
   "source": [
    "You may also want to store your path in a path object for easy access like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe824f24-e409-43a3-b610-97381f52c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/anthonyspinelli/Desktop/pace-university-eco-590-classroom-707af1-eco-590-assignments-Data-Analysis-in-R-and-Python-Eco-590-main/Lectures/Week_4'\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285d816-6d17-4693-9fff-df7329d3d7f3",
   "metadata": {},
   "source": [
    "# For Windows users\n",
    "your paths might look a bit diffrent with C:// at the front, its the same as on mac but paths are just denoted a bit diffrently.\n",
    "\n",
    "Also in the past ive had to switch slasshes over from back slash to foreward after copying, you maye have the same issues: \"\\\\\" to \"/\"\n",
    "\n",
    "See the Lecture 4 jupyter file for more detailed info on pathing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacbb6ae-d286-4188-b698-40423eb101ed",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362caab-0201-40ee-9fc7-f9032d36edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + '/ds/wjp.csv')\n",
    "\n",
    "# This is the same as using the full path:\n",
    "df = pd.read_csv('/Users/anthonyspinelli/Desktop/pace-university-eco-590-classroom-707af1-eco-590-assignments-Data-Analysis-in-R-and-Python-Eco-590-main/Lectures/Week_4/ds/wjp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71eef9-af2d-40cd-9c5c-9366f44d5a26",
   "metadata": {},
   "source": [
    "# Other Options for importing data:\n",
    "\n",
    "pd.read_csv() - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "for read_csv (as well as others) we can set the seperator - pd.read_csv(path, sep = ',')\n",
    "\n",
    "we can also set the encoding\n",
    "\n",
    "pd.read_csv(path, encoding = 'utf-8')\n",
    "\n",
    "Most files you wont have to set either of these, but if you have importing issues, you will have to play around to find the correct seperator and encoding. Most are utf-8 encoding and comma deliminated\n",
    "\n",
    "You may also have to tell read_csv which line is the header, with the header = 0 option\n",
    "\n",
    "pd.read_excel()\n",
    "\n",
    "read_excel, is for excel files. you can set get diffrent sheets if the file has multiple with the sheet_name option - pd.read_excel(path, sheet_name = 'Sheet 1')\n",
    "\n",
    "\n",
    "Some other data saving options:\n",
    "<img src ='images/utf-8csv.png' width=500 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0262f-8364-4260-ab1c-cb53f8f5c16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cadded-5966-4398-b151-c85b50757f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d870c1-a0b7-44fc-97a0-8a4dcbeca032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first thing we can do with imported data is look at it!\n",
    "# From this we see a row count and column count at the bottom, as well as some of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8812a-07c2-4552-8ab8-884ba87a0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also see what columns are in the data with:\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f9754-5960-44df-8208-52a61c0f4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting individual columns\n",
    "df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed02cc2-40e3-4344-8018-eade4414f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both work the same, it depends on the name of the column\n",
    "df.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef50957-d2bd-416b-b850-1fe395469b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Income Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ff686-962f-4c35-b762-382b9c49ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Income Group # This doesnt work because of the space in column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd31a76-6395-4e1e-a2df-a6ea2e6065a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to just see the first few rows, we can do:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2dd8b2-4915-4f9f-8f99-7d658e0de6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as well as the last few rows:\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6be50-50e4-4d92-a504-bb75c3992c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also change how many we want to see:\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804ee44-13e2-4338-ae92-904ecbcd4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can rename columns lise so:\n",
    "df = df.rename(columns = {'year':'date','Country':'state'})\n",
    "df\n",
    "\n",
    "# remember, you need to assign the new data to another variable. renaming it back to the original df works fine, but sometimes you'll want to make a diffrent name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abbda4-a16d-4623-b786-cd5de9de5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can replace things in the data like so, for whole columns (df.replace(,))\n",
    "\n",
    "import numpy as np\n",
    "df = df.replace('Australia',np.nan)\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ceced-f771-440f-b892-5417ca06c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can drop null values like so:\n",
    "df2 = df.dropna()\n",
    "print(len(df2))\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f465826-f7f7-4090-a0ff-23e15b2bafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('THIS WAS NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca2e03-457c-4597-9c11-e3327640028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get only specific columns:\n",
    "df[['state','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d21ad-f381-499a-99f1-6c4219879ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find all the unique rows in a column\n",
    "df.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf336d-2a89-4c12-9285-0d1e44799469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the unique things in a column\n",
    "df['Income Group'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b8c94-8120-4774-a97a-37c8aa1992f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use value_counts to see whats inside of a column\n",
    "df['Income Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedbe2e-4b78-4544-a261-347458981a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values\\\n",
    "df.sort_values('factor1', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2a813-b255-48e3-82a9-9a7a8cbce67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('factor1', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ea270-d61a-435c-b0c9-e70d7fdb7b7d",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d071e9e-6c5b-4fd2-957d-60f2d2ae1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.state == 'Albania']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe614368-5f59-40b0-ac05-2a44be02438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Income Group'] == 'Lower middle income') & (df.factor1 <= .40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f3617-162d-4550-b5a1-0a2ac42704e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also get some descriptave stats with .describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d2c55-652f-4b30-bc44-4c3c51fb795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can take means and other estimates\n",
    "df.factor1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b804e4-f4cc-42be-9281-315ff79f4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.factor1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ff3c4-7e09-466b-9be5-2a1fe437f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.factor1.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9c80d-97e0-447d-b3cd-fc87c0c2f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "# Often you will want to reset the index of the data when merging and performing other operations\n",
    "df3 = df[df['Income Group'] == 'Lower middle income'].reset_index(drop=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea4f0e-c9f0-4a6f-b35b-3fa59f40eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also set the index to whichever column we would like\n",
    "df.set_index('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abb571-61c2-422c-bc4d-de3e5e42faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To specifically drop columns\n",
    "df.drop(columns = {'state','Region'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75c20d-6deb-4c01-9574-ee491dfa7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also create new columns\n",
    "df['new_column'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b27241-a9bc-464f-971c-97db5491be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add new columns based on a filter\n",
    "df.loc[df['Income Group'] == 'High income','high_inc_binary'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15215589-e348-4df0-ad1a-ec93bed86e22",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2794e-2603-4ad6-b527-ee9741849299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFten, you will want to concat data together. lets do an example\n",
    "df1 = df[['Country','Region','factor1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2489d9-2eea-433b-9a9b-2ec607f0f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns = {'factor1','Country','Region'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a13ed7-002a-489d-8a05-4d55053d3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ee17a-152d-45e1-b808-4da6481584bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9543b-348b-47bc-b3b6-5a29b0849421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we are missing some of our data. Lets put it back together!\n",
    "df = pd.concat([df1,df2],axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede096a-d737-4762-8dd3-750c05a9f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The other way\n",
    "df1 = df[df.Region == 'Eastern Europe & Central Asia'].assign(binary = 0)\n",
    "df2 = df[df.Region != 'Eastern Europe & Central Asia'].assign(binary = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a97f9c-3fe4-4235-872f-760578bdd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2], axis = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39996aed-4ec8-48e0-bf37-402a1f9991d6",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb37dbf-8b33-4311-a6f2-ebb124af96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wjp = pd.read_csv(path+ '/ds/wjp.csv') \n",
    "ineq = pd.read_csv(path+ '/ds/ineq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66652f79-e64d-4859-9110-f073744eb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wjp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b3c96-57be-4eaf-bfce-2bef121218ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ineq.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6f8a8-b298-427f-bd83-5267d7150081",
   "metadata": {},
   "outputs": [],
   "source": [
    "wjp_ineq = pd.merge(wjp, ineq, left_on=['Country','year'],\n",
    "                    right_on=['country','year'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e55ffc-2ae3-4e2e-aaa8-0d916508c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wjp_ineq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f87fc3-9744-4309-9251-f49e4701c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "wjp_ineq.to_csv(path + '/data_export.csv', index = False)\n",
    "\n",
    "# notice the index = False\n",
    "# If we want to include the index we turn that option to true\n",
    "# It is true by default!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7606d0d-545c-4f15-a792-b66e1178880c",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c28810-c9ef-445e-9ffb-5dfc1d6addc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "wjp = pd.read_csv(path + '/ds/wjp.csv') \n",
    "ineq = pd.read_csv(path + '/ds/ineq.csv') \n",
    "wjp_ineq = pd.merge(wjp, ineq, left_on=['Country','year'],\n",
    "                    right_on=['country','year'],how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a82e6-9f66-454d-bdb5-dedfc32656cb",
   "metadata": {},
   "source": [
    "Filter out the dataset to show only data from the region Sub Saharan Africa \n",
    "\n",
    "How many countries are in the region?\n",
    "\n",
    "Calculate the average gini of the region.\n",
    "\n",
    "What's the maximum population in the region? What's the countries name?\n",
    "\n",
    "write a for loop that calculates the total countries in, mean gini coeficent, and maximum population for each region\n",
    "\n",
    "Export the filtered dataset for Sub Saharan Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590fda5-58c1-4c3a-b5b3-16a6fa7f6057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c1067-819c-439e-9b6d-93b38a026148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b48fd-82b2-40ee-90f1-d628d4cc1515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b73bf-e96a-4ebe-a068-150de908cb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1bff4-b7f1-4065-a890-f64b92ddc535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7035c9-4417-41d7-a47b-5cecc8ccaa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06eb75-f83d-4ffb-a83d-c74ebf3f69f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552bba4-3548-492d-99e4-f6214dd28529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "904bb8f2-596a-48a2-9f23-1e6ce6f9f44f",
   "metadata": {},
   "source": [
    "# Tons of Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c551f78-1c72-4181-a194-0ff3a2e1a994",
   "metadata": {},
   "source": [
    "Next, lets read in a lot of data from a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9c159-c763-45de-bdb6-5e305fc7940d",
   "metadata": {},
   "source": [
    "### Method 1 - for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b478a-700b-49ca-a265-d88167f6541a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let's build a for loop to look through these files and to append them\n",
    "path_firm ='/Users/anthonyspinelli/Desktop/pace-university-eco-590-classroom-707af1-eco-590-assignments-Data-Analysis-in-R-and-Python-Eco-590-main/Lectures/Week_4/ds/firm_size_state_industry/'\n",
    "# defining the pathname for this exercise\n",
    "out =[] # Creating an empty list\n",
    "\n",
    "for year in range(2007,2018): #looping through years because the file structure is the same except for the year\n",
    "    data = pd.read_csv(str(path_firm)+'us_state_6digitnaics_'+str(year)+'.txt',encoding='latin1') # Reading in the data\n",
    "    data['year'] = year # Creating a new column called year for the year of the data\n",
    "\n",
    "    out.append(data)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98c702-4102-4c9b-8279-1659949cc1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woah thats messy we need to concat the data together into a dataframe\n",
    "e = pd.concat(out, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc763f-9904-48a9-9622-f11f0c175051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643ab2a-7ead-4715-9232-439989ae87c6",
   "metadata": {},
   "source": [
    "# Method 2 - os library\n",
    "\n",
    "I love this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d7e7c1-fc4e-4db8-babd-1a02c106dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098cb26-4775-47cd-9685-0e10c1137f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(path_firm+'*.txt') # We first get all the paths with the ending .txt\n",
    "paths = [x for x in paths] # Then using list comprehension, we get all those paths in a list\n",
    "\n",
    "out = [] # Create our out object\n",
    "for path in paths: # For loop it up\n",
    "    data = pd.read_csv(path,encoding='latin1') # Import the path\n",
    "    year_of_data = path.split('.txt')[0].split('_')[-1] # create a year variable from the path\n",
    "    data['year'] = year_of_data # create a new column for the data\n",
    "\n",
    "    out.append(data) # Append the file after its read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff1890-e15e-4eb9-a230-7fb7a81b872c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = pd.concat(out,axis = 0)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8d7e4-47fc-48b3-aa5d-1edc8d71d3a1",
   "metadata": {},
   "source": [
    "### Pivots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb465a-60a4-4e69-a3c9-ed8abfa7bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm filtering so that I look at only the national information about firms size by industry\n",
    "firm_data = e[(e['STATE']==0)& (e['NAICS']!= '--')& (e['NAICS']!= '99')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4770-0286-4436-b4f3-3fffebfdbdf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "firm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd162fc0-ce32-454b-a227-a80eb7aee0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll explain this in the next section - for now hold off on questions on this magic.\n",
    "firm_data_grouped=firm_data[['NAICS','FIRM','EMPL','year']].drop_duplicates().groupby(['NAICS','year']).sum().reset_index()\n",
    "\n",
    "firm_data_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c56ce-9fcf-45a5-9b70-dedcb105135a",
   "metadata": {},
   "source": [
    "Sometimes you might find that you need to change the way the data is presented.\n",
    "\n",
    "Data can be stored \"long\" or \"wide\" - largely, how you want to display the information depends on what you are doing.\n",
    "\n",
    "Generally, I work with long data because of the way most programs read data for regression analysis.\n",
    "\n",
    "<img src= \"images/long_wide.png\">\n",
    "\n",
    "Often, you'll want to change the format of the data. There are a few ways that you can do this.\n",
    "\n",
    "Also, pivot is excel's best feature to easily manipulate data in that program. It is basically python's groupby feature combined with pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a0633-5291-4995-89cc-858eeaf32eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows are industry\n",
    "firm_data_grouped.pivot(index='NAICS',columns='year', values='EMPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265afa8-2bba-45ef-aa9a-da0b9f3fd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_data_grouped.pivot(index='year',columns='NAICS', values='FIRM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d7bfb-eea0-440c-bcf5-c92508e2a972",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "\n",
    "Pandas makes statistics by grouping variables very easy. This will be something that you will do often (as shown above). It's VERY convenient and makes doing statistics super easy. \n",
    "\n",
    "Essentially, the process is split-apply-combine (also exists in R)\n",
    "\n",
    "<img src ='images/groupby.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1458b-c979-4bde-ac0e-260bdd426b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(firm_data))\n",
    "firm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e1678-0b32-4da2-b82b-c0ca6d55c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are getting the sum of employment stats for each industry for each year\n",
    "df = firm_data[['NAICS','EMPL','year']].groupby(['year','NAICS']).sum().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e14df8-5dd6-46f8-a2f5-b92b8639ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line filters for information just about the industry, firm size, and year\n",
    "firm_data[['NAICS','FIRM','EMPL', 'year']]\n",
    "\n",
    "#the function below drops any duplicate values that might exist\n",
    ".drop_duplicates()\n",
    "\n",
    "# this function groups (splits) the information by industry and year\n",
    ".groupby(['NAICS','year'])\n",
    "\n",
    "# this function applies the way of which you want to calculate the data\n",
    ".sum()\n",
    "\n",
    "#this function resets the index (not necessary, but good to know about how to use it when you want to combine this data )\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98cfb5-ecd1-43ad-9395-0d5b70f0704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets say I wanted to calculate the percentage change for employment statistics for the industry 11\n",
    "# We can use the .pct_change() to do so: \n",
    "code_11 = df[df.NAICS == '11']\n",
    "\n",
    "change = code_11['EMPL'].pct_change()\n",
    "\n",
    "# Lets add that back into our dataframe\n",
    "\n",
    "code_11['change'] = change\n",
    "\n",
    "code_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494e7e1-6e71-45fa-8334-5f9855a7c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can do it without python yelling at us\n",
    "\n",
    "df.loc[df.NAICS == '11','change'] = df[df.NAICS == '11']['EMPL'].pct_change()\n",
    "code_11 = df[df.NAICS == '11']\n",
    "code_11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7396e-d453-46e1-8e85-d26f5507e113",
   "metadata": {},
   "source": [
    "# Building for loops with data, step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749cf403-3d01-423b-9292-b79b26c757a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate the pct change for each industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5a011-5f7d-4c48-9a0a-c36db4ec89e2",
   "metadata": {},
   "source": [
    "1. examine our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09b403-c0b7-4d4d-9590-3131faff3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# We see a bunch of diffrent NAICS codes, lets look at how many their are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b73c79-12f6-46dc-b657-1ef1d25ffc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NAICS.value_counts()\n",
    "# 518111 only appears once, lets look at that one to see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02696ae-150d-483f-a151-66c6485d9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.NAICS == '518111']\n",
    "# It only appears once, lets see if that skrews up the pct_change() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2148be-b71d-48d3-b3c2-75500a0ae079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.NAICS == '518111'].EMPL.pct_change()\n",
    "# It does not so we should be fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4932e8-f1fd-4b71-bf51-0ba44396196f",
   "metadata": {},
   "source": [
    "2. Think about our goal - a dataset that has each NAICS industry and its pct change for the years its in the data\n",
    "\n",
    "So lets start with a point example by using one industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e4f41-a0a1-4e02-97c7-e7a8493e4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.NAICS == '81399']\n",
    "# okay we see some 0, so could be missing data. Lets get rid of those\n",
    "df = df[df.EMPL != 0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97db199-9f7f-41a2-80b2-8a51cd37f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still building from our point example, lets calculate the pct change and add it back to this dataset\n",
    "subset_data = df[df.NAICS == '81399']\n",
    "subset_data = subset_data.sort_values('year',ascending = True) # sort ascending to make sure we are going in the right direction\n",
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273563ac-f288-4337-8527-735e5a67a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_change = subset_data.EMPL.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06976bde-18bf-499f-b6e4-e12dda8a4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data['pct_chg'] = percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bcaa0c-73e4-4af0-8e6c-cd9516ba3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data\n",
    "# Cool thats what we want for each. Now lets build our loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151d4eb-7d5f-48fd-8e49-dfae9812b1a9",
   "metadata": {},
   "source": [
    "3. next lets get our list of NAICS industries to loop through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c95cc-c6a2-4e97-971c-cabc324f7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_list = df.NAICS.drop_duplicates().reset_index(drop=True)\n",
    "NAICS_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5af53e-cb6b-4a18-a01b-75e8e0d760ce",
   "metadata": {},
   "source": [
    "4. Loop it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e6f5a-c484-4a63-8070-6bb2f820766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [] # create our out to append to\n",
    "\n",
    "for industry in NAICS_list: # Start our loop over the industry list we made\n",
    "    subset_data = df[df.NAICS == industry].sort_values('year', ascending = True)\n",
    "    percent_change = subset_data.EMPL.pct_change()\n",
    "    final_data = subset_data.assign(pct_chg = percent_change) # We'll use assign because it doesnt give us a warning\n",
    "    out.append(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee76132-5cde-4c4f-ab71-d1265970553e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out\n",
    "# out is gross again so lets pd.concat it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3709a23-6096-4bcc-8413-290c75f7beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change_dataset = pd.concat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ada16-92c4-423d-acf9-848669a9baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change_dataset\n",
    "# and there we go\n",
    "# lastly lets just check the row count against the original dataset to make sure we didnt mess anything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01dc83-0486-444c-9166-8e3fd32a40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afd26f-9529-49bb-9b1a-db3b481f66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pct_change_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d8fe8-a4f3-4290-ab3c-5cef294f7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9df31-3f91-4839-9365-7142232dd03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a90ee9-c36a-4960-a415-ebce72ae93de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b8bbb-8282-4401-a775-4c77aa522dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ac3bd-cf1c-45f2-9f60-cb61aed50ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cc6ca-5f91-46c6-ac54-52cc60c09a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd655e33-ddc4-4c94-977c-843b2aa79b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d18e96-84b5-4a21-b799-13f56ff9b563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080750d9-7589-466a-8af6-ceeaad0a2398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
